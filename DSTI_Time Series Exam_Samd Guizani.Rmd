---
title: "Time Series - EXAM"
author: "Samd Guizani"
date: "`r Sys.Date()`"
output: word_document
---

# Assignment

-   File 2023-11-Elec-train.xlsx contains electricity consumption (kW) and outdoor air temperature for a building., measured every 15 minutes, from 1/1/2010 1:15 to 2/20/2010 23:45.

-   In addition, outdoor air temperature are available for 2/21/2010. The goal is to forecast electricity consumption (kW) for 2/21/2010.

-   Two forecasts should be returned, in one Excel file entitled YourName.xlsx, with exactly two columns (one columns per forecast) and 96 rows:

    1)  first one without using outdoor temperature

    2)  the second one using outdoor temperature.

# Working directory and imports

```{r}
setwd("~/DSTI_MSc DS and AI/02-Foundation/06-Time Series/Exam")

library(readxl)
library(forecast)
library(funtimes) # trend tests
library(ggplot2)
library(imputeTS) # imputing missing data in a time series (interpolation)
library(randomForest)
library(xgboost)
library(e1071) # SVM
library(vars) # VAR model
```

# Load data and explore

## Plot time series and evaluate trends and seasonality patterns

```{r}
data = read_excel('2023-11-Elec-train.xlsx')
data$Timestamp <- as.POSIXct(data[[1]], format = "%m/%d/%Y %H:%M")
data$Timestamp[1] <- as.POSIXct("1/1/2010 1:15", format = "%m/%d/%Y %H:%M") # fix import issue with 1st timestamp.

ts_power = ts(data$`Power (kW)`[1:(dim(data)[1] - 96)], start = 1, freq = 96) # last 96 obs are NA, to be forecasted

autoplot(ts_power)
autoplot(ts_power) + xlim(c(45, 50)) # focus on unusual data 
ggseasonplot(ts_power) # seasonal plot with daily period
ggseasonplot(ts(ts_power, freq = 7 * 96)) # seasonal plot with weekly period

ts_temperature = ts(data$`Temp (CÂ°)`, start = 1, freq = 96)
autoplot(ts_temperature)
ggseasonplot(ts_temperature)
```

#### Notes:

-   Power shows a daily and weekly periodic pattern. No obvious trend or possibly a slight decreasing trend. Variance seems constant over time. Unusual zero values (around day 49, i.e. 2/18/2010).

-   Temperature shows a daily periodic pattern. A possible increasing trend.

```{r fig.height=4.5, fig.width=8}
i = 1 + 96 * 0
n_days = 51
ts_temporary = ts(data$`Power (kW)`[i:(i+96*n_days-1)], start = 1, freq = 96)
ggseasonplot(ts_temporary) + xlim(0.75,1)

```

#### Notes:

-   Power daily pattern is comparable during 6 of the week days, but the 7th day has a specific pattern (earlier decrease during Friday)

## Replace unusual values by interpolation

```{r}
# focus on power values at zero
loc_0s = which(ts_power == 0)
ts_power_impute = ts_power
ts_power_impute[loc_0s] = NA
ts_power_impute = imputeTS::na_interpolation(ts_power_impute, option = 'linear')

autoplot(ts_power) + 
  autolayer(ts_power_impute) +
  xlim(c(45, 50))

ts_power_impute[loc_0s]
```

#### Notes:

-   Replacing 0 values by interpolated values seems reasonable.

## Time series decomposition and differentiating

```{r}
plot(decompose(ts_power_impute)) # daily period
plot(decompose(ts(ts_power_impute, frequency = 7*96))) # weekly period
```

#### Notes:

-   Decomposing based on daily period: still a seasonal pattern in the random series (period of 7 days, i.e. weekly) as well as in the trend component.

-   Decomposing based on weekly period: trend component looks smooth with no seasonal pattern. Random component still shows daily pattern (-\> information need to be modeled)

```{r}
ggtsdisplay(diff(ts_power_impute, lag = 96, differences = 1)) # daily period
ggtsdisplay(diff(diff(ts_power_impute, lag = 96, differences = 1),
                 lag = 1,
                 differences = 1)) # daily period + diff with lag 1

ggtsdisplay(diff(ts_power_impute, lag = 7 * 96, differences = 1)) # weekly period
ggtsdisplay(diff(diff(ts_power_impute, lag = 7 * 96, differences = ), 
                 lag = 1, 
                 differences = 1)) # weekly period + diff with lag 1

```

#### Notes:

-   Differentiating with a lag of a day period: still observe a weekly seasonal pattern (see time series plot)

-   Differentiating twice (with a lag of a day period + lag = 1 for de-trending): still observe a weekly seasonal pattern (see time series plot)

-   Differentiating with a lag of a week period: periodic pattern no longer observed, but a trend is still visible (see time series plot).

-   Differentiating twice (with a lag of a week period + lag = 1 for de-trending): time series centered on 0, no visible trend. ACF/PACF show significant autocorrelation values (-\> information to be modeled)

# Modeling (without covariates)

```{r}
# Converting ts_power_impute to daily period
y_daily = ts(ts_power_impute, frequency = 96)
y_daily_train = head(y_daily, length(y_daily) - 96)
y_daily_test = tail(y_daily, 96)

# Converting ts_power_impute to weekly period
y_weekly = ts(ts_power_impute, frequency = 7*96)
y_weekly_train = head(y_weekly, length(y_daily) - 96)
y_weekly_test = tail(y_weekly, 96)
```

## Holt-Winters, Daily period

```{r}
# exec_t_start = Sys.time()
# 
# fit = hw(y_daily_train, h=96, seasonal = "additive")
# fit |>  summary()
# 
# ggtsdisplay(fit$residuals)
# checkresiduals(fit, plot = TRUE)
# 
# exec_t_end = Sys.time()
# print(exec_t_end - exec_t_start)
```

## SARIMA (auto), Daily period

```{r}
# Auto ARIMA, daily period
exec_t_start = Sys.time()

fit = auto.arima(y_daily_train)
fit |>  summary()

ggtsdisplay(fit$residuals)
checkresiduals(fit, plot = TRUE)

exec_t_end = Sys.time()
print(exec_t_end - exec_t_start)
```

```{r}
# saveRDS(fit, file = "ARIMA_auto_(5,0,0)(0,1,0)[96].rds")
```

## SARIMA (manual), Daily period

```{r}
# ARIMA, daily period
exec_t_start = Sys.time()

fit = Arima(y_daily_train, order = c(5,1,5), seasonal = c(0,1,1))
fit |>  summary()

ggtsdisplay(fit$residuals)
checkresiduals(fit, plot = TRUE)

exec_t_end = Sys.time()
print(exec_t_end - exec_t_start)
```

```{r}
# saveRDS(fit, file = "ARIMA_man_(5,1,5)(0,1,1)[96].rds")
```

## NNetAR, Daily period

```{r}
exec_t_start = Sys.time()

fit = nnetar(y_daily_train)
fit |>  summary()

e = fit$residuals
print(paste0("Train RMSE: ", sqrt(mean(e^2, na.rm = TRUE))))
ggtsdisplay(fit$residuals)
checkresiduals(fit, plot = TRUE)

exec_t_end = Sys.time()
print(exec_t_end - exec_t_start)
```

```{r}
# saveRDS(fit, file = "NNetAR_daily.rds")
```

## SARIMA (auto), Weekly period

```{r}
# Auto ARIMA, weekly period
exec_t_start = Sys.time()

fit = auto.arima(y_weekly_train)
fit |>  summary()

ggtsdisplay(fit$residuals)
checkresiduals(fit, plot = TRUE)

exec_t_end = Sys.time()
print(exec_t_end - exec_t_start)
```

```{r}
# saveRDS(fit, file = "ARIMA_auto_(5,1,2)(0,1,0)[672].rds")
```

## SARIMA (manual), Weekly period

```{r}
# ARIMA, weekly period
# exec_t_start = Sys.time()
# 
# fit = Arima(y_weekly_train, order = c(5,1,2), seasonal = c(1,1,0))
# fit |>  summary()
# 
# ggtsdisplay(fit$residuals)
# checkresiduals(fit, plot = TRUE)
# 
# exec_t_end = Sys.time()
# print(exec_t_end - exec_t_start)
```

```{r}
# saveRDS(fit, file = "ARIMA_auto_(5,1,2)(1,1,0)[672].rds")
```

## NetAR, Weekly period

```{r}
exec_t_start = Sys.time()

fit = nnetar(y_weekly_train)
fit |>  summary()

e = fit$residuals
print(paste0("Train RMSE: ", sqrt(mean(e^2, na.rm = TRUE))))
ggtsdisplay(fit$residuals)
checkresiduals(fit, plot = TRUE)

exec_t_end = Sys.time()
print(exec_t_end - exec_t_start)
```

```{r}
# saveRDS(fit, file = "NNetAR_weekly.rds")
```

```{r}

# x = co2
# 
# forecastfunction = function(x, h){forecast(Arima(x, order=c(1,0,0)), h=h)}
# 
# e = tsCV(co2, forecastfunction, h = 12, window = 5, xreg = NULL, initial = 150)



# #Fit an AR(2) model to each rolling origin subset
# far2 <- function(x, h){forecast(Arima(x, order=c(2,0,0)), h=h)}
# e <- tsCV(lynx, far2, h=1)
# 
# #Fit the same model with a rolling window of length 30
# e <- tsCV(lynx, far2, h=1, window=30)
# 
# #Example with exogenous predictors
# far2_xreg <- function(x, h, xreg, newxreg) {
#   forecast(Arima(x, order=c(2,0,0), xreg=xreg), xreg=newxreg)
# }
# 
# y <- ts(rnorm(50))
# xreg <- matrix(rnorm(100),ncol=2)
# e <- tsCV(y, far2_xreg, h=3, xreg=xreg)


```

```{r}
# autoplot(window(fit$fitted, start = 30)) + autolayer(window(ts_power_impute, start = 30))
```

```{r}
# exec_t_start = Sys.time()
# 
# forecastfunc = function(x, h)
# {
#   forecast(Arima(x, order=c(0,1,0), seasonal=c(0,1,0)),
#            h=h,
#            window = 2 * 96 * 7, # condider 2 weeks history to build a model
#            initial = 3000) 
# }
# 
# e = tsCV(y_daily_train, forecastfunc, h=96)
# 
# exec_t_end = Sys.time()
# print(exec_t_end - exec_t_start)
```

## ML data prep

```{r}
# next observation based on last day
df_daily = as.vector(y_daily_train)[1:(96+1)]
for (i in 1:(length(y_daily_train)-(96+1)))
{
  df_daily = rbind(df_daily, as.vector(y_daily_train)[(i+1):(i+96+1)])
}

# next observation based on last week
df_weekly = as.vector(y_weekly_train)[1:(7*96+1)]
for (i in 1:(length(y_weekly_train)-(7*96+1)))
{
  df_weekly = rbind(df_weekly, as.vector(y_weekly_train)[(i+1):(i+7*96+1)])
}

# next 96 observations based on 2 last week
df_2weeks = as.vector(y_weekly_train)[1:(2*7*96+96)]
for (i in 1:(length(y_weekly_train)-(2*7*96+96)))
{
  df_2weeks = rbind(df_2weeks, as.vector(y_weekly_train)[(i+1):(i+2*7*96+96)])
}
```

## ML - Random Forest, Daily period

```{r}
exec_t_start = Sys.time()

fit = randomForest(x = df_daily[,-(96+1)], y = df_daily[, (96+1)])
fit |>  summary()

e = ts(fit$y - fit$predicted, start = c(1,1), frequency = 96)
print(paste0("Train RMSE: ", sqrt(mean(e^2, na.rm = TRUE))))
ggtsdisplay(e)
checkresiduals(e, plot = TRUE)

exec_t_end = Sys.time()
print(exec_t_end - exec_t_start)

# saveRDS(fit, file = "RF_daily.rds")
```

## ML - XGBoost, Daily period

```{r}
exec_t_start = Sys.time()

fit = xgboost(data = df_daily[,-(96+1)], label = df_daily[, (96+1)],
              max_depth = 10,
              eta = 0.5,
              nrounds = 100,
              objective = "reg:squarederror")
fit |>  summary()

e = ts(df_daily[, (96+1)] - predict(fit, newdata = df_daily[,-(96+1)]), start = c(1,1), frequency = 96)
print(paste0("Train RMSE: ", sqrt(mean(e^2, na.rm = TRUE))))
ggtsdisplay(e)
checkresiduals(e, plot = TRUE)

exec_t_end = Sys.time()
print(exec_t_end - exec_t_start)

# saveRDS(fit, file = "XGBoost_daily.rds")
```

## ML - Random Forest, Weekly period

```{r}
exec_t_start = Sys.time()

fit = randomForest(x = df_weekly[,-(7*96+1)], y = df_weekly[, (7*96+1)])
fit |>  summary()

e = ts(fit$y - fit$predicted, start = c(1,1), frequency = 96)
print(paste0("Train RMSE: ", sqrt(mean(e^2, na.rm = TRUE))))
ggtsdisplay(e)
checkresiduals(e, plot = TRUE)

exec_t_end = Sys.time()
print(exec_t_end - exec_t_start)

# saveRDS(fit, file = "RF_weekly.rds")
```

## ML - XGBoost, Weekly period

```{r}
exec_t_start = Sys.time()

fit = xgboost(data = df_weekly[,-(7*96+1)], label = df_weekly[, (7*96+1)],
              max_depth = 10,
              eta = 0.5,
              nrounds = 100,
              objective = "reg:squarederror")
fit |>  summary()

e = ts(df_weekly[, (7*96+1)] - predict(fit, newdata = df_weekly[,-(7*96+1)]), start = c(1,1), frequency = 96)
print(paste0("Train RMSE: ", sqrt(mean(e^2, na.rm = TRUE))))
ggtsdisplay(e)
checkresiduals(e, plot = TRUE)

exec_t_end = Sys.time()
print(exec_t_end - exec_t_start)

# saveRDS(fit, file = "XGBoost_weeky.rds")
```

## ML - PLS, 2 weeks history to forecast next day

```{r}
library(pls)
```

```{r}
exec_t_start = Sys.time()

fit = plsr(df_2weeks[,(2*7*96+1):(2*7*96+96)] ~ df_2weeks[,1:(2*7*96)],
           scale = TRUE,
           validation = "CV")
fit |>  summary()

# Cross-validation results
validation_mse <- fit$validation$PRESS
avg_mse <- colMeans(validation_mse)

# Optimal components minimizing average MSE
optimal_ncomp <- which.min(avg_mse)

e = fit$residuals[,,optimal_ncomp]
print(paste0("Train RMSE: ", sqrt(mean(e^2, na.rm = TRUE))))
# ggtsdisplay(e)
# checkresiduals(e, plot = TRUE)

exec_t_end = Sys.time()
print(exec_t_end - exec_t_start)

# saveRDS(fit, file = "PLS_2weeks.rds")
```

#### Notes:

-   PLS: Very long fitting time (approx. 6h). And produces a huge object (+11 GB)

-   Train RMSE = 8.41923 (optimal_ncomp = 144)
